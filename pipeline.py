# pipeline.py
from s3.fetch_data import fetch_place_info, fetch_reviews
from preprocess.deduplicate_places import deduplicate_places
from preprocess.filter_columns import filter_columns
from preprocess.clean_text import clean_text
from preprocess.extract_nouns import extract_nouns_from_reviews
from preprocess.validate_reviews import validate_reviews
from preprocess.csv_to_json import convert_to_json
from db.init_collections import init_collections
from db.insert_data import insert_data
from utils.logger import get_logger


logger = get_logger("pipeline")

def run_pipeline(region_csv_path: str):
    try:
        logger.info("ğŸš€ Step 1: S3ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
        df_place_info_raw = fetch_place_info()
        df_reviews_raw = fetch_reviews()
    except Exception as e:
        logger.error(f"âŒ S3 ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ” Step 2: ì¤‘ë³µ place_id ì²˜ë¦¬ ë° ë¦¬ë·° í•„í„°ë§ ì¤‘...")
        df_place_dedup, df_reviews_dedup, _ = deduplicate_places(df_place_info_raw, df_reviews_raw)
    except Exception as e:
        logger.error(f"âŒ ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ“‘ Step 3: ì»¬ëŸ¼ í•„í„°ë§...")
        df_place_filtered, df_reviews_filtered = filter_columns(df_place_dedup, df_reviews_dedup)
    except Exception as e:
        logger.error(f"âŒ ì»¬ëŸ¼ í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ§¼ Step 4: ë¦¬ë·° í…ìŠ¤íŠ¸ í´ë Œì§•...")
        df_reviews_cleaned = clean_text(df_reviews_filtered)
    except Exception as e:
        logger.error(f"âŒ í…ìŠ¤íŠ¸ í´ë Œì§• ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ§  Step 5: ëª…ì‚¬ ì¶”ì¶œ ë° ë¶ˆìš©ì–´ ì œê±°...")
        df_reviews_nouns = extract_nouns_from_reviews(df_reviews_cleaned)
    except Exception as e:
        logger.error(f"âŒ ëª…ì‚¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("âœ… Step 6: ìœ íš¨ ë¦¬ë·°ë§Œ í•„í„°ë§...")
        df_reviews_valid = validate_reviews(df_reviews_nouns)
    except Exception as e:
        logger.error(f"âŒ ìœ íš¨ ë¦¬ë·° í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ“¦ Step 7: JSON ë³€í™˜ ì¤‘...")
        place_info_json, reviews_json = convert_to_json(df_place_filtered, df_reviews_valid)
    except Exception as e:
        logger.error(f"âŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸŒ Step 8: ì§€ì—­êµ¬ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”...")
        init_collections(region_csv_path)
    except Exception as e:
        logger.error(f"âŒ ì§€ì—­êµ¬ ì»¬ë ‰ì…˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    try:
        logger.info("ğŸ“¤ Step 9: MongoDBì— ë°ì´í„° ì ì¬ ì¤‘...")
        insert_data(place_info_json, reviews_json)
    except Exception as e:
        logger.error(f"âŒ MongoDB ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")
        return

    logger.info("ğŸ‰ ëª¨ë“  ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ë° MongoDB ì €ì¥ ì™„ë£Œ!")

# ì‹¤í–‰ (python pipeline.py)
if __name__ == "__main__":
    run_pipeline("data/adm_dong_list.csv")