from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from google.oauth2 import service_account
import pandas as pd
import io
import os
import json
from dotenv import load_dotenv
from utils.logger import get_logger  # ë¡œê·¸ ì¶”ê°€

load_dotenv(dotenv_path='env/.env')

# ë¡œê¹…
logger = get_logger("fetch_data")

# êµ¬ê¸€ ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ
SERVICE_ACCOUNT_FILE = os.getenv("GOOGLE_SERVICE_ACCOUNT_FILE")
SCOPES = ["https://www.googleapis.com/auth/drive.readonly"]

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„±
creds = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_FILE, scopes=SCOPES
)
drive_service = build("drive", "v3", credentials=creds)


def list_files_in_folder(folder_id):
    """êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë” ì•ˆì˜ ëª¨ë“  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§• ì²˜ë¦¬ í¬í•¨)"""
    query = f"'{folder_id}' in parents and mimeType='application/json' and trashed=false"
    all_files = []
    page_token = None

    while True:
        response = drive_service.files().list(
            q=query,
            fields="nextPageToken, files(id, name)",
            pageSize=500,  # í•œ ë²ˆì— ìµœëŒ€ 500ê°œ
            pageToken=page_token
        ).execute()

        all_files.extend(response.get("files", []))
        page_token = response.get("nextPageToken")

        if not page_token:
            break  # ë” ì´ìƒ ë‹¤ìŒ í˜ì´ì§€ ì—†ìœ¼ë©´ ì¢…ë£Œ

    return all_files

def download_json_file(file_id):
    """íŒŒì¼ IDë¡œ JSON íŒŒì¼ ë‹¤ìš´ë¡œë“œ í›„ pandas DataFrameìœ¼ë¡œ ë³€í™˜"""
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        status, done = downloader.next_chunk()
    fh.seek(0)
    data = json.load(fh)
    return pd.json_normalize(data)  # JSONì„ DataFrameìœ¼ë¡œ ë³€í™˜


def fetch_and_concat_from_gdrive(folder_id):
    """í´ë” ID ë‚´ì˜ ëª¨ë“  JSON íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  í•©ì¹˜ê¸°"""
    files = list_files_in_folder(folder_id)
    files.sort(key=lambda x: x["name"])  # íŒŒì¼ ì´ë¦„ìˆœ ì •ë ¬

    df_list = []
    for idx, file in enumerate(files, 1):
        try:
            df = download_json_file(file["id"])
            df_list.append(df)
            logger.info(f"[{idx}/{len(files)}] ğŸ“¥ {file['name']} ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ {file['name']} ë¡œë“œ ì‹¤íŒ¨: {e}")

    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()


def fetch_place_info():
    place_info_folder_id = os.getenv("PLACE_INFO_FOLDER_ID")
    return fetch_and_concat_from_gdrive(place_info_folder_id)


def fetch_reviews():
    reviews_folder_id = os.getenv("REVIEWS_FOLDER_ID")
    return fetch_and_concat_from_gdrive(reviews_folder_id)
